{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27843579",
   "metadata": {},
   "source": [
    "Here are all the data cleaning steps.\n",
    "\n",
    "1. Get urls from several directories. \n",
    "    - The directories were - jasmine, w3newspapers, usnpl\n",
    "2. Collate all urls together.\n",
    "3. Extract base urls of all these urls. This creates the \"raw dataset\".\n",
    "4. Enrich data of a base url if it is in multiple directories (i.e) if one directory has state info and another has topic info, then make sure the variables is populated in all rows against that url.\n",
    "5. Dedupe these base urls across directories. This creates the \"urls list\".\n",
    "    - To keep track if certain urls exist across states, a separate \"collated dataset\" is created which has states data and n repeats for n states.\n",
    "6. Check how many requests of `https://[base url]/ads.txt` are successful. The successful urls form the \"valid urls\" list\n",
    "7. Out of the \"valid urls\" account for redirects.\n",
    "    - If the base url has a valid redirect to an actual ads.txt file, then that base url enters the \"valid redirects\" list .\n",
    "    - If it doesn't lead to an ads.txt directly, but instead to a new base url, then check if that new base url leads to a valid ads.txt. If it does, then create a mapping file from old to new base urls and this new base url should enter the \"valid redirects list\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2385198d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests as req\n",
    "from urllib.parse import urlparse\n",
    "import os\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a6b6a9",
   "metadata": {},
   "source": [
    "## 1. Get urls from several directories\n",
    "\n",
    "Step 1 was done separately. Some of it was manual work. We start from step 2 below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251e24ba",
   "metadata": {},
   "source": [
    "## 2. Collate all urls together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878d8760",
   "metadata": {},
   "source": [
    "### 2.1 Tidying up Jasmine directory dataset for collation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05e79c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Magazine :  41\n",
      "Political News :  62\n",
      "Sports :  47\n",
      "Newspapers :  60\n",
      "Television :  42\n"
     ]
    }
   ],
   "source": [
    "#This code is from here: https://stackoverflow.com/a/64759478/10098211\n",
    "def get_sheetnames_xlsx(filepath):\n",
    "    wb = load_workbook(filepath, read_only=True, keep_links=False)\n",
    "    return wb.sheetnames\n",
    "\n",
    "filepath = \"./data/Jasmine directory.xlsx\"\n",
    "sheet_names = get_sheetnames_xlsx(filepath)\n",
    "dfs_list = []\n",
    "for sheet in sheet_names:\n",
    "    df = pd.read_excel(filepath, sheet, header=None, names=['URL'])\n",
    "    print(sheet, \": \", len(df))\n",
    "    df['Topic'] = sheet\n",
    "    dfs_list.append(df)\n",
    "jasmine = pd.concat(dfs_list)\n",
    "\n",
    "#adding a column just to keep track of things\n",
    "jasmine['directory'] = 'Jasmine'\n",
    "\n",
    "#Lowercasing colnames just to keep life simple in final concat\n",
    "jasmine.columns = [name.lower() for name in jasmine.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ea4fd8",
   "metadata": {},
   "source": [
    "### 2.2 Tidying up W3 directory dataset for collation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbe9631b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>states</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alabama</td>\n",
       "      <td>https://www.alexcityoutlook.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alabama</td>\n",
       "      <td>https://www.annistonstar.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alabama</td>\n",
       "      <td>https://www.al.com/birmingham/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    states                               url\n",
       "0  alabama  https://www.alexcityoutlook.com/\n",
       "1  alabama     https://www.annistonstar.com/\n",
       "2  alabama    https://www.al.com/birmingham/"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"./data/allnewslisturl.xlsx\"\n",
    "w3 = pd.read_excel(filepath)\n",
    "w3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d85afb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting statecodes\n",
    "state_codes_path = \"./data/us_state_codes.html\" #Got it from https://www23.statcan.gc.ca/imdb/p3VD.pl?Function=getVD&TVD=53971\n",
    "state_codes = pd.read_html(\"./data/us_state_codes.html\")[0]\n",
    "state_codes.State = state_codes.State.str.lower()\n",
    "state_codes.drop(['Code', 'Abbreviation'], inplace=True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "358023fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning up state names for better merge\n",
    "w3.states = w3.states.str.replace('-', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ddbddf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merging\n",
    "w3 = w3.merge(state_codes, left_on = 'states', right_on = 'State', how='left')\n",
    "w3.drop(['states'], axis = 1, inplace = True)\n",
    "w3.loc[w3['Alpha code'].isna(), :].State.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3aefd19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding a column just to keep track of things\n",
    "w3['directory'] = 'w3'\n",
    "\n",
    "#Lowercasing colnames just to keep life simple in final concat\n",
    "w3.columns = [name.lower() for name in w3.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190e5f9c",
   "metadata": {},
   "source": [
    "### 2.3 Tidying up USNPL directory dataset for collation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95ef1dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Newspaper URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>http://www.sandmountainreporter.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>http://www.alexcityoutlook.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL</td>\n",
       "      <td>http://www.andalusiastarnews.com/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State                         Newspaper URL\n",
       "0    AL  http://www.sandmountainreporter.com/\n",
       "1    AL       http://www.alexcityoutlook.com/\n",
       "2    AL     http://www.andalusiastarnews.com/"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"./data/USNPL_newswebsite_urls.txt\"\n",
    "usnpl = pd.read_csv(filepath, sep='|')\n",
    "usnpl.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfab988f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Getting statenames\n",
    "usnpl = usnpl.merge(state_codes, left_on = 'State', right_on = 'Alpha code', how='left')\n",
    "usnpl.drop(['State_x'], inplace=True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2eff1cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>state</th>\n",
       "      <th>alpha code</th>\n",
       "      <th>directory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.sandmountainreporter.com/</td>\n",
       "      <td>alabama</td>\n",
       "      <td>AL</td>\n",
       "      <td>usnpl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.alexcityoutlook.com/</td>\n",
       "      <td>alabama</td>\n",
       "      <td>AL</td>\n",
       "      <td>usnpl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.andalusiastarnews.com/</td>\n",
       "      <td>alabama</td>\n",
       "      <td>AL</td>\n",
       "      <td>usnpl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    url    state alpha code directory\n",
       "0  http://www.sandmountainreporter.com/  alabama         AL     usnpl\n",
       "1       http://www.alexcityoutlook.com/  alabama         AL     usnpl\n",
       "2     http://www.andalusiastarnews.com/  alabama         AL     usnpl"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding a column just to keep track of things\n",
    "usnpl['directory'] = 'usnpl'\n",
    "\n",
    "#Lowercasing colnames just to keep life simple in final concat\n",
    "usnpl.columns = [name.lower() for name in usnpl.columns]\n",
    "\n",
    "#Name cleanup for final concat to work\n",
    "usnpl.columns = w3.columns\n",
    "\n",
    "usnpl.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bcb372",
   "metadata": {},
   "source": [
    "### 2.4 Collating all 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "538ee19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "collated_df = pd.concat([jasmine, w3, usnpl])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bbe6b7",
   "metadata": {},
   "source": [
    "## 3. Extract base urls of all these urls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "571d3c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>topic</th>\n",
       "      <th>directory</th>\n",
       "      <th>state</th>\n",
       "      <th>alpha code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5436</th>\n",
       "      <td>http://www.torringtontelegram.com/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>usnpl</td>\n",
       "      <td>wyoming</td>\n",
       "      <td>WY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5437</th>\n",
       "      <td>http://www.pcrecordtimes.com/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>usnpl</td>\n",
       "      <td>wyoming</td>\n",
       "      <td>WY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5438</th>\n",
       "      <td>http://www.wyodaily.com/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>usnpl</td>\n",
       "      <td>wyoming</td>\n",
       "      <td>WY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     url topic directory    state alpha code\n",
       "5436  http://www.torringtontelegram.com/   NaN     usnpl  wyoming         WY\n",
       "5437       http://www.pcrecordtimes.com/   NaN     usnpl  wyoming         WY\n",
       "5438            http://www.wyodaily.com/   NaN     usnpl  wyoming         WY"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Basic cleanup of url column\n",
    "collated_df.url = collated_df.url.str.strip()\n",
    "collated_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42e03ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_www(x):\n",
    "    if x.startswith('www') or x.startswith('ww1'):\n",
    "        return x[4:]\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efe8d052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>topic</th>\n",
       "      <th>directory</th>\n",
       "      <th>state</th>\n",
       "      <th>alpha code</th>\n",
       "      <th>base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://beezzly.com/</td>\n",
       "      <td>Magazine</td>\n",
       "      <td>Jasmine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>beezzly.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.elle.com/</td>\n",
       "      <td>Magazine</td>\n",
       "      <td>Jasmine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>elle.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.gaming.net</td>\n",
       "      <td>Magazine</td>\n",
       "      <td>Jasmine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gaming.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://pingbacklinks.com</td>\n",
       "      <td>Magazine</td>\n",
       "      <td>Jasmine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pingbacklinks.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.inthesnow.com/</td>\n",
       "      <td>Magazine</td>\n",
       "      <td>Jasmine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inthesnow.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          url     topic directory state alpha code  \\\n",
       "0        https://beezzly.com/  Magazine   Jasmine   NaN        NaN   \n",
       "1       https://www.elle.com/  Magazine   Jasmine   NaN        NaN   \n",
       "2      https://www.gaming.net  Magazine   Jasmine   NaN        NaN   \n",
       "3   https://pingbacklinks.com  Magazine   Jasmine   NaN        NaN   \n",
       "4  https://www.inthesnow.com/  Magazine   Jasmine   NaN        NaN   \n",
       "\n",
       "                base  \n",
       "0        beezzly.com  \n",
       "1           elle.com  \n",
       "2         gaming.net  \n",
       "3  pingbacklinks.com  \n",
       "4      inthesnow.com  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collated_df['base'] = collated_df['url'].apply(lambda x: urlparse(x).netloc)\n",
    "collated_df['base'] = collated_df['base'].apply(lambda x: remove_www(x))\n",
    "collated_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfe18d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "collated_df.to_csv(\"./data/raw_data.txt\", sep='|', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573a3651",
   "metadata": {},
   "source": [
    "## 4. Enrich data of a base url if it is in multiple directories \n",
    "(i.e) if one directory has state info and another has topic info, then make sure the variables are populated in all rows against that url."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a104be",
   "metadata": {},
   "source": [
    "In the process of doing this I wanna make sure I don't generate additional duplicates. So I am going to declare a function to keep an eye on the dupes. This will also help me when I actively dedupe in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e27811dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_dupe_counter(df, var, lvl_var = 'base'):\n",
    "    counts = df.groupby(lvl_var).nunique()\n",
    "    multi_var_urls = list(counts.loc[counts[var] > 1].index)\n",
    "    multi_var_urls_df = df.loc[(df[lvl_var]).isin(multi_var_urls),:].sort_values(lvl_var)\n",
    "    multi_var_urls_count_df = pd.DataFrame(multi_var_urls_df.groupby(lvl_var).count()[var]).reset_index()\n",
    "\n",
    "    print(f\"No of dupes across {var}:\", len(multi_var_urls))\n",
    "    print(\"No of rows:\", len(multi_var_urls_df))\n",
    "    print(\"Breakdown on no of rows: \\n\", pd.DataFrame(multi_var_urls_count_df.groupby(var).count()).reset_index())\n",
    "    print(\"The df is returned if you want it...\")\n",
    "    return multi_var_urls_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "574043dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of dupes across directory: 2184\n",
      "No of rows: 5174\n",
      "Breakdown on no of rows: \n",
      "     directory  base\n",
      "0           2  1908\n",
      "1           3   146\n",
      "2           4    55\n",
      "3           5    23\n",
      "4           6    11\n",
      "5           7     9\n",
      "6           8     5\n",
      "7           9     9\n",
      "8          10     4\n",
      "9          11     1\n",
      "10         12     1\n",
      "11         13     4\n",
      "12         14     1\n",
      "13         15     1\n",
      "14         16     1\n",
      "15         17     1\n",
      "16         21     1\n",
      "17         38     1\n",
      "18         43     1\n",
      "19         56     1\n",
      "The df is returned if you want it...\n"
     ]
    }
   ],
   "source": [
    "status_df = var_dupe_counter(collated_df, var = 'directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3a71f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of dupes across state: 55\n",
      "No of rows: 313\n",
      "Breakdown on no of rows: \n",
      "     state  base\n",
      "0       2    12\n",
      "1       3    13\n",
      "2       4    14\n",
      "3       5     3\n",
      "4       6     5\n",
      "5       7     1\n",
      "6       9     2\n",
      "7      10     1\n",
      "8      11     1\n",
      "9      21     1\n",
      "10     36     1\n",
      "11     43     1\n",
      "The df is returned if you want it...\n"
     ]
    }
   ],
   "source": [
    "status_df = var_dupe_counter(collated_df, var = 'state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04240d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current nulls:  192 \n",
      "Earlier nulls:  252\n"
     ]
    }
   ],
   "source": [
    "#Populating state everywhere I can\n",
    "nonull_state = collated_df.loc[~collated_df['state'].isna(), ['base', 'state']]\n",
    "nonull_state = nonull_state.drop_duplicates()\n",
    "collated_df2 = collated_df.merge(nonull_state, how='left', left_on='base', right_on ='base')\n",
    "\n",
    "#Removing additional column and renaming it\n",
    "collated_df2 = collated_df2.drop(['state_x'], axis = 1) \n",
    "ind = list(collated_df2.columns).index('state_y')\n",
    "colnames = list(collated_df2.columns)\n",
    "colnames[ind] = 'state'\n",
    "collated_df2.columns = colnames\n",
    "\n",
    "#Removing obvious dupes\n",
    "collated_df2 = collated_df2.drop_duplicates()\n",
    "\n",
    "#Checking if nulls decreased\n",
    "print(\"Current nulls: \", len(collated_df2.loc[collated_df2.state.isna(),:]), \n",
    "      \"\\nEarlier nulls: \", len(collated_df.loc[collated_df.state.isna(),:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d356d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current nulls:  9464 \n",
      "Earlier nulls:  9650\n"
     ]
    }
   ],
   "source": [
    "#Populating topic everywhere I can\n",
    "nonull_topic = collated_df2.loc[~collated_df2['topic'].isna(), ['base', 'topic']]\n",
    "nonull_topic = nonull_topic.drop_duplicates()\n",
    "collated_df3 = collated_df2.merge(nonull_topic, how='left', left_on='base', right_on ='base')\n",
    "\n",
    "#Removing additional column and renaming it\n",
    "collated_df3 = collated_df3.drop('topic_x', axis = 1)\n",
    "ind = list(collated_df3.columns).index('topic_y')\n",
    "colnames = list(collated_df3.columns)\n",
    "colnames[ind] = 'topic'\n",
    "collated_df3.columns = colnames\n",
    "\n",
    "#Removing obvious dupes\n",
    "collated_df3 = collated_df3.drop_duplicates()\n",
    "\n",
    "#Checking if nulls decreased\n",
    "print(\"Current nulls: \", len(collated_df3.loc[collated_df3.topic.isna(),:]), \n",
    "      \"\\nEarlier nulls: \",len(collated_df2.loc[collated_df2.topic.isna(),:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eaf32427",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>alpha code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>alabama</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>florida</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>georgia</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>alaska</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>arizona</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9837</th>\n",
       "      <td>oregon</td>\n",
       "      <td>WI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9838</th>\n",
       "      <td>pennsylvania</td>\n",
       "      <td>WI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9839</th>\n",
       "      <td>tennessee</td>\n",
       "      <td>WI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9840</th>\n",
       "      <td>texas</td>\n",
       "      <td>WI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9841</th>\n",
       "      <td>washington</td>\n",
       "      <td>WI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>679 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             state alpha code\n",
       "248        alabama         AL\n",
       "256        florida         AL\n",
       "263        georgia         AL\n",
       "337         alaska         AK\n",
       "369        arizona         AZ\n",
       "...            ...        ...\n",
       "9837        oregon         WI\n",
       "9838  pennsylvania         WI\n",
       "9839     tennessee         WI\n",
       "9840         texas         WI\n",
       "9841    washington         WI\n",
       "\n",
       "[679 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#State code issue\n",
    "collated_df3[['state', 'alpha code']].drop_duplicates().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a2659d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dealing with state code issue\n",
    "collated_df3 = collated_df3.merge(state_codes, how = 'left', left_on='state', right_on = 'State')\n",
    "collated_df3.drop(['alpha code', 'State'], axis=1, inplace=True)\n",
    "collated_df3.columns = [col.lower() for col in collated_df3.columns]\n",
    "collated_df3 = collated_df3.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef89176a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>alpha code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>new york</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>virginia</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>district of columbia</td>\n",
       "      <td>DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>massachusetts</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>california</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>georgia</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>maryland</td>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>illinois</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>indiana</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>ohio</td>\n",
       "      <td>OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>colorado</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>michigan</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>connecticut</td>\n",
       "      <td>CT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>texas</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>kansas</td>\n",
       "      <td>KS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>missouri</td>\n",
       "      <td>MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>kentucky</td>\n",
       "      <td>KY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>wisconsin</td>\n",
       "      <td>WI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>minnesota</td>\n",
       "      <td>MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>louisiana</td>\n",
       "      <td>LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>new jersey</td>\n",
       "      <td>NJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>oregon</td>\n",
       "      <td>OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>florida</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>pennsylvania</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>alabama</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>alaska</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>arizona</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>nevada</td>\n",
       "      <td>NV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>arkansas</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>delaware</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>south carolina</td>\n",
       "      <td>SC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>hawaii</td>\n",
       "      <td>HI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>idaho</td>\n",
       "      <td>ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>washington</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>utah</td>\n",
       "      <td>UT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>iowa</td>\n",
       "      <td>IA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>maine</td>\n",
       "      <td>ME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>new hampshire</td>\n",
       "      <td>NH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>west virginia</td>\n",
       "      <td>WV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>north dakota</td>\n",
       "      <td>ND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732</th>\n",
       "      <td>mississippi</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>new mexico</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1873</th>\n",
       "      <td>north carolina</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877</th>\n",
       "      <td>tennessee</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889</th>\n",
       "      <td>montana</td>\n",
       "      <td>MT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>nebraska</td>\n",
       "      <td>NE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>south dakota</td>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2104</th>\n",
       "      <td>vermont</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2512</th>\n",
       "      <td>oklahoma</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2730</th>\n",
       "      <td>rhode island</td>\n",
       "      <td>RI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3410</th>\n",
       "      <td>wyoming</td>\n",
       "      <td>WY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     state alpha code\n",
       "30                new york         NY\n",
       "37                virginia         VA\n",
       "43    district of columbia         DC\n",
       "94           massachusetts         MA\n",
       "121             california         CA\n",
       "149                georgia         GA\n",
       "150               maryland         MD\n",
       "151               illinois         IL\n",
       "152                indiana         IN\n",
       "153                   ohio         OH\n",
       "158               colorado         CO\n",
       "159               michigan         MI\n",
       "162            connecticut         CT\n",
       "163                  texas         TX\n",
       "166                 kansas         KS\n",
       "167               missouri         MO\n",
       "169               kentucky         KY\n",
       "170              wisconsin         WI\n",
       "171              minnesota         MN\n",
       "172              louisiana         LA\n",
       "176             new jersey         NJ\n",
       "179                 oregon         OR\n",
       "180                florida         FL\n",
       "182           pennsylvania         PA\n",
       "236                alabama         AL\n",
       "325                 alaska         AK\n",
       "357                arizona         AZ\n",
       "358                 nevada         NV\n",
       "413               arkansas         AR\n",
       "776               delaware         DE\n",
       "860         south carolina         SC\n",
       "933                 hawaii         HI\n",
       "964                  idaho         ID\n",
       "969             washington         WA\n",
       "999                   utah         UT\n",
       "1077                  iowa         IA\n",
       "1360                 maine         ME\n",
       "1466         new hampshire         NH\n",
       "1509         west virginia         WV\n",
       "1653          north dakota         ND\n",
       "1732           mississippi         MS\n",
       "1872            new mexico         NM\n",
       "1873        north carolina         NC\n",
       "1877             tennessee         TN\n",
       "1889               montana         MT\n",
       "1922              nebraska         NE\n",
       "1924          south dakota         SD\n",
       "2104               vermont         VT\n",
       "2512              oklahoma         OK\n",
       "2730          rhode island         RI\n",
       "3410               wyoming         WY"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#State code issue resolved\n",
    "collated_df3[['state', 'alpha code']].drop_duplicates().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a58129b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of dupes across directory: 2184\n",
      "No of rows: 6254\n",
      "Breakdown on no of rows: \n",
      "     directory  base\n",
      "0           2  1949\n",
      "1           3   100\n",
      "2           4    61\n",
      "3           5    17\n",
      "4           6     9\n",
      "5           7     7\n",
      "6           8    10\n",
      "7           9     5\n",
      "8          10     4\n",
      "9          11     1\n",
      "10         12     5\n",
      "11         13     3\n",
      "12         14     1\n",
      "13         15     2\n",
      "14         16     2\n",
      "15         17     1\n",
      "16         18     1\n",
      "17         20     2\n",
      "18         38     1\n",
      "19         56     1\n",
      "20         72     1\n",
      "21       1032     1\n",
      "The df is returned if you want it...\n"
     ]
    }
   ],
   "source": [
    "status_df = var_dupe_counter(collated_df3, var = 'directory')\n",
    "#Same no of dupes just more rows..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0354a34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of dupes across state: 55\n",
      "No of rows: 313\n",
      "Breakdown on no of rows: \n",
      "     state  base\n",
      "0       2    12\n",
      "1       3    13\n",
      "2       4    14\n",
      "3       5     3\n",
      "4       6     5\n",
      "5       7     1\n",
      "6       9     2\n",
      "7      10     1\n",
      "8      11     1\n",
      "9      21     1\n",
      "10     36     1\n",
      "11     43     1\n",
      "The df is returned if you want it...\n"
     ]
    }
   ],
   "source": [
    "status_df = var_dupe_counter(collated_df, var = 'state')\n",
    "#Same number of dupes but lesser number of rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e894a89",
   "metadata": {},
   "source": [
    "## 5. Dedupe the base urls across directories. This creates the \"urls list\".\n",
    "    - To keep track if certain urls exist across states, a separate \"collated dataset\" is created which has states data and n repeats for n states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "720de123",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of dupes across directory: 2184\n",
      "No of rows: 6254\n",
      "Breakdown on no of rows: \n",
      "     directory  base\n",
      "0           2  1949\n",
      "1           3   100\n",
      "2           4    61\n",
      "3           5    17\n",
      "4           6     9\n",
      "5           7     7\n",
      "6           8    10\n",
      "7           9     5\n",
      "8          10     4\n",
      "9          11     1\n",
      "10         12     5\n",
      "11         13     3\n",
      "12         14     1\n",
      "13         15     2\n",
      "14         16     2\n",
      "15         17     1\n",
      "16         18     1\n",
      "17         20     2\n",
      "18         38     1\n",
      "19         56     1\n",
      "20         72     1\n",
      "21       1032     1\n",
      "The df is returned if you want it...\n"
     ]
    }
   ],
   "source": [
    "#Dupes status across directories\n",
    "status_df = var_dupe_counter(collated_df3, 'directory', lvl_var = 'base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d7e3c03",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of dupes across state: 55\n",
      "No of rows: 1493\n",
      "Breakdown on no of rows: \n",
      "     state  base\n",
      "0       2     4\n",
      "1       4    26\n",
      "2       6     4\n",
      "3       8     6\n",
      "4      10     2\n",
      "5      12     4\n",
      "6      14     1\n",
      "7      15     1\n",
      "8      16     2\n",
      "9      18     1\n",
      "10     20     1\n",
      "11     38     1\n",
      "12     72     1\n",
      "13   1032     1\n",
      "The df is returned if you want it...\n"
     ]
    }
   ],
   "source": [
    "#Dupes status across states\n",
    "status_df = var_dupe_counter(collated_df3, 'state', lvl_var = 'base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b165ea56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base\n",
      "bizjournals.com    True\n",
      "Name: state, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Checking in on the crazy 1032 dupes url...\n",
    "print((collated_df3.groupby('base').count()['state'] == 1032).loc[lambda x: x == True])\n",
    "#Writing it out to look at all 1032 rows\n",
    "collated_df3.loc[collated_df3['base'] == 'bizjournals.com'].to_csv('temp.txt', sep = '|', index=False)\n",
    "\n",
    "#I got what is happening here. It is legit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f5fa191",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deduping across directories. To ensure states data isn't lost, it is included in drop logic...\n",
    "deduped_collated_df = collated_df3.drop_duplicates(['base', 'state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "620e0434",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of dupes across directory: 0\n",
      "No of rows: 0\n",
      "Breakdown on no of rows: \n",
      " Empty DataFrame\n",
      "Columns: [directory, base]\n",
      "Index: []\n",
      "The df is returned if you want it...\n"
     ]
    }
   ],
   "source": [
    "#Dupes status across directories\n",
    "status_df = var_dupe_counter(deduped_collated_df, 'directory', lvl_var = 'base')\n",
    "#Perfect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a38bbc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of dupes across state: 55\n",
      "No of rows: 135\n",
      "Breakdown on no of rows: \n",
      "    state  base\n",
      "0      2    52\n",
      "1      3     1\n",
      "2      4     1\n",
      "3     24     1\n",
      "The df is returned if you want it...\n"
     ]
    }
   ],
   "source": [
    "#Dupes status across states\n",
    "status_df = var_dupe_counter(deduped_collated_df, 'state', lvl_var = 'base')\n",
    "#So state repeat data isn't lost. Good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a94ae357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing it out\n",
    "deduped_collated_df['base'].drop_duplicates().to_csv('./data/urls_list.txt', sep='|', index=False)\n",
    "deduped_collated_df.to_csv('./data/collated_data.txt', sep='|', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4c4a33",
   "metadata": {},
   "source": [
    "## 6. Check how many requests of `https://[base url]/ads.txt` are successful. The successful urls form the \"valid urls\" list\n",
    "\n",
    "Since this involves multithreading, it is done in a separate python script - See `checking_for_adstxt.py`. The response codes are outputted by that script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "635b801a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_url</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://okmagazine.com/ads.txt</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://failuremag.com/ads.txt</td>\n",
       "      <td>HTTPSConnectionPool(host='failuremag.com', por...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://pingbacklinks.com/ads.txt</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://elle.com/ads.txt</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://menswearstyle.co.uk/ads.txt</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              full_url  \\\n",
       "0       https://okmagazine.com/ads.txt   \n",
       "1       https://failuremag.com/ads.txt   \n",
       "2    https://pingbacklinks.com/ads.txt   \n",
       "3             https://elle.com/ads.txt   \n",
       "4  https://menswearstyle.co.uk/ads.txt   \n",
       "\n",
       "                                            response  \n",
       "0                                                200  \n",
       "1  HTTPSConnectionPool(host='failuremag.com', por...  \n",
       "2                                                200  \n",
       "3                                                200  \n",
       "4                                                403  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_codes = pd.read_csv('./data/responses.txt', sep='|', names = ['full_url', 'response'])\n",
    "response_codes.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b3d1681b",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_urls = response_codes.loc[(response_codes['response'] == '200')]['full_url'].apply(lambda x: urlparse(x).netloc)\n",
    "valid_urls.name = 'base'\n",
    "valid_urls.to_csv('./data/valid_urls.txt', sep='|', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac087ff5",
   "metadata": {},
   "source": [
    "## 7. Out of the \"valid urls\" account for redirects.\n",
    "    - If the base url has a valid redirect to an actual ads.txt file, then that base url enters the \"valid redirects\" list .\n",
    "    - If it doesn't lead to an ads.txt directly, but instead to a new base url, then check if that new base url leads to a valid ads.txt. If it does, then create a mapping file called `redirect mappings` from old to new base urls and this new base url should enter the \"valid redirects list\"\n",
    "\n",
    "This needs parallelization. So it is done separately in a script - See `validating_redirects.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ead6624c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_url</th>\n",
       "      <th>base_url</th>\n",
       "      <th>redirect</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://okmagazine.com/ads.txt</td>\n",
       "      <td>okmagazine.com</td>\n",
       "      <td>https://okmagazine.com/ads.txt</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://vanityfair.com/ads.txt</td>\n",
       "      <td>vanityfair.com</td>\n",
       "      <td>https://vanityfair.com/ads.txt</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://nytimes.com/ads.txt</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>https://www.nytimes.com/ads.txt</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://pingbacklinks.com/ads.txt</td>\n",
       "      <td>pingbacklinks.com</td>\n",
       "      <td>https://pingbacklinks.com/ads.txt</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://thewalrus.ca/ads.txt</td>\n",
       "      <td>thewalrus.ca</td>\n",
       "      <td>https://thewalrus.ca/ads.txt</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           query_url           base_url  \\\n",
       "0     https://okmagazine.com/ads.txt     okmagazine.com   \n",
       "1     https://vanityfair.com/ads.txt     vanityfair.com   \n",
       "2        https://nytimes.com/ads.txt        nytimes.com   \n",
       "3  https://pingbacklinks.com/ads.txt  pingbacklinks.com   \n",
       "4       https://thewalrus.ca/ads.txt       thewalrus.ca   \n",
       "\n",
       "                            redirect status  \n",
       "0     https://okmagazine.com/ads.txt      y  \n",
       "1     https://vanityfair.com/ads.txt      y  \n",
       "2    https://www.nytimes.com/ads.txt      y  \n",
       "3  https://pingbacklinks.com/ads.txt      y  \n",
       "4       https://thewalrus.ca/ads.txt      y  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redirects_response = pd.read_csv('./data/redirects_response.txt', sep='|')\n",
    "redirects_response.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "93eca66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "n       2\n",
      "y    2894\n",
      "Name: base_url, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(redirects_response.groupby('status').count()['base_url'])\n",
    "\n",
    "#Ignoring the 2\n",
    "redirects_response = redirects_response[redirects_response['status'] == 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e8655dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Does the base url have a valid redirect to an actual ads.txt?\n",
    "redirects_response['valid_redirect'] = redirects_response['redirect'].apply(lambda x: x.__contains__('txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "974087f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_url</th>\n",
       "      <th>base_url</th>\n",
       "      <th>redirect</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid_redirect</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>378</td>\n",
       "      <td>378</td>\n",
       "      <td>378</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>2516</td>\n",
       "      <td>2516</td>\n",
       "      <td>2516</td>\n",
       "      <td>2516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                query_url  base_url  redirect  status\n",
       "valid_redirect                                       \n",
       "False                 378       378       378     378\n",
       "True                 2516      2516      2516    2516"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redirects_response.groupby('valid_redirect').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1449b1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ports(x):\n",
    "    if x.__contains__(':'):\n",
    "        x = x[:-4]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "96138b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_url</th>\n",
       "      <th>base_url</th>\n",
       "      <th>redirect</th>\n",
       "      <th>status</th>\n",
       "      <th>valid_redirect</th>\n",
       "      <th>base_redirect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://okmagazine.com/ads.txt</td>\n",
       "      <td>okmagazine.com</td>\n",
       "      <td>https://okmagazine.com/ads.txt</td>\n",
       "      <td>y</td>\n",
       "      <td>True</td>\n",
       "      <td>okmagazine.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://vanityfair.com/ads.txt</td>\n",
       "      <td>vanityfair.com</td>\n",
       "      <td>https://vanityfair.com/ads.txt</td>\n",
       "      <td>y</td>\n",
       "      <td>True</td>\n",
       "      <td>vanityfair.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://nytimes.com/ads.txt</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>https://www.nytimes.com/ads.txt</td>\n",
       "      <td>y</td>\n",
       "      <td>True</td>\n",
       "      <td>nytimes.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://pingbacklinks.com/ads.txt</td>\n",
       "      <td>pingbacklinks.com</td>\n",
       "      <td>https://pingbacklinks.com/ads.txt</td>\n",
       "      <td>y</td>\n",
       "      <td>True</td>\n",
       "      <td>pingbacklinks.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://thewalrus.ca/ads.txt</td>\n",
       "      <td>thewalrus.ca</td>\n",
       "      <td>https://thewalrus.ca/ads.txt</td>\n",
       "      <td>y</td>\n",
       "      <td>True</td>\n",
       "      <td>thewalrus.ca</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           query_url           base_url  \\\n",
       "0     https://okmagazine.com/ads.txt     okmagazine.com   \n",
       "1     https://vanityfair.com/ads.txt     vanityfair.com   \n",
       "2        https://nytimes.com/ads.txt        nytimes.com   \n",
       "3  https://pingbacklinks.com/ads.txt  pingbacklinks.com   \n",
       "4       https://thewalrus.ca/ads.txt       thewalrus.ca   \n",
       "\n",
       "                            redirect status  valid_redirect      base_redirect  \n",
       "0     https://okmagazine.com/ads.txt      y            True     okmagazine.com  \n",
       "1     https://vanityfair.com/ads.txt      y            True     vanityfair.com  \n",
       "2    https://www.nytimes.com/ads.txt      y            True        nytimes.com  \n",
       "3  https://pingbacklinks.com/ads.txt      y            True  pingbacklinks.com  \n",
       "4       https://thewalrus.ca/ads.txt      y            True       thewalrus.ca  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting base urls from the redirects\n",
    "redirects_response['base_redirect'] = redirects_response['redirect'].apply(lambda x: urlparse(x).netloc)\n",
    "redirects_response['base_redirect'] = redirects_response['base_redirect'].apply(lambda x: remove_www(x))\n",
    "redirects_response['base_redirect'] = redirects_response['base_redirect'].apply(lambda x: remove_ports(x))\n",
    "redirects_response.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "092bf18b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_url</th>\n",
       "      <th>base_url</th>\n",
       "      <th>redirect</th>\n",
       "      <th>status</th>\n",
       "      <th>valid_redirect</th>\n",
       "      <th>base_redirect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>https://leanleft.com/ads.txt</td>\n",
       "      <td>leanleft.com</td>\n",
       "      <td>https://tortdeform.com/category/free-consultat...</td>\n",
       "      <td>y</td>\n",
       "      <td>False</td>\n",
       "      <td>tortdeform.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>https://thelafayettesun.com/ads.txt</td>\n",
       "      <td>thelafayettesun.com</td>\n",
       "      <td>https://wilcoxnewspapers.com/sun/</td>\n",
       "      <td>y</td>\n",
       "      <td>False</td>\n",
       "      <td>wilcoxnewspapers.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>https://gazettes.com/ads.txt</td>\n",
       "      <td>gazettes.com</td>\n",
       "      <td>https://www.presstelegram.com/the-grunion/</td>\n",
       "      <td>y</td>\n",
       "      <td>False</td>\n",
       "      <td>presstelegram.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>https://bhcourier.com/ads.txt</td>\n",
       "      <td>bhcourier.com</td>\n",
       "      <td>https://beverlyhillscourier.com/</td>\n",
       "      <td>y</td>\n",
       "      <td>False</td>\n",
       "      <td>beverlyhillscourier.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>https://gorizont.com/ads.txt</td>\n",
       "      <td>gorizont.com</td>\n",
       "      <td>https://view.publitas.com/hmg-llc/gorizont-44-...</td>\n",
       "      <td>y</td>\n",
       "      <td>False</td>\n",
       "      <td>view.publitas.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2832</th>\n",
       "      <td>https://recordstar.com/ads.txt</td>\n",
       "      <td>recordstar.com</td>\n",
       "      <td>https://www.usatoday.com/</td>\n",
       "      <td>y</td>\n",
       "      <td>False</td>\n",
       "      <td>usatoday.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>https://oregonherald.com/ads.txt</td>\n",
       "      <td>oregonherald.com</td>\n",
       "      <td>https://139.162.49.128/</td>\n",
       "      <td>y</td>\n",
       "      <td>False</td>\n",
       "      <td>139.162.49.128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2866</th>\n",
       "      <td>https://dptribune.com/ads.txt</td>\n",
       "      <td>dptribune.com</td>\n",
       "      <td>https://www.statesmanexaminer.com/dptribune/</td>\n",
       "      <td>y</td>\n",
       "      <td>False</td>\n",
       "      <td>statesmanexaminer.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>https://planetjh.com/ads.txt</td>\n",
       "      <td>planetjh.com</td>\n",
       "      <td>https://buckrail.com</td>\n",
       "      <td>y</td>\n",
       "      <td>False</td>\n",
       "      <td>buckrail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2894</th>\n",
       "      <td>https://wcregisteronline.com/ads.txt</td>\n",
       "      <td>wcregisteronline.com</td>\n",
       "      <td>https://kampusbola.id/</td>\n",
       "      <td>y</td>\n",
       "      <td>False</td>\n",
       "      <td>kampusbola.id</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 query_url              base_url  \\\n",
       "210           https://leanleft.com/ads.txt          leanleft.com   \n",
       "228    https://thelafayettesun.com/ads.txt   thelafayettesun.com   \n",
       "327           https://gazettes.com/ads.txt          gazettes.com   \n",
       "336          https://bhcourier.com/ads.txt         bhcourier.com   \n",
       "393           https://gorizont.com/ads.txt          gorizont.com   \n",
       "...                                    ...                   ...   \n",
       "2832        https://recordstar.com/ads.txt        recordstar.com   \n",
       "2833      https://oregonherald.com/ads.txt      oregonherald.com   \n",
       "2866         https://dptribune.com/ads.txt         dptribune.com   \n",
       "2892          https://planetjh.com/ads.txt          planetjh.com   \n",
       "2894  https://wcregisteronline.com/ads.txt  wcregisteronline.com   \n",
       "\n",
       "                                               redirect status  \\\n",
       "210   https://tortdeform.com/category/free-consultat...      y   \n",
       "228                   https://wilcoxnewspapers.com/sun/      y   \n",
       "327          https://www.presstelegram.com/the-grunion/      y   \n",
       "336                    https://beverlyhillscourier.com/      y   \n",
       "393   https://view.publitas.com/hmg-llc/gorizont-44-...      y   \n",
       "...                                                 ...    ...   \n",
       "2832                          https://www.usatoday.com/      y   \n",
       "2833                            https://139.162.49.128/      y   \n",
       "2866       https://www.statesmanexaminer.com/dptribune/      y   \n",
       "2892                               https://buckrail.com      y   \n",
       "2894                             https://kampusbola.id/      y   \n",
       "\n",
       "      valid_redirect            base_redirect  \n",
       "210            False           tortdeform.com  \n",
       "228            False     wilcoxnewspapers.com  \n",
       "327            False        presstelegram.com  \n",
       "336            False  beverlyhillscourier.com  \n",
       "393            False        view.publitas.com  \n",
       "...              ...                      ...  \n",
       "2832           False             usatoday.com  \n",
       "2833           False           139.162.49.128  \n",
       "2866           False    statesmanexaminer.com  \n",
       "2892           False             buckrail.com  \n",
       "2894           False            kampusbola.id  \n",
       "\n",
       "[201 rows x 6 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting invalid redirects wherein base url and base of redirect url are not the same\n",
    "condition = ~(redirects_response['valid_redirect'] == True) & ~(redirects_response['base_redirect'] == \n",
    "                                                               redirects_response['base_url'])\n",
    "redirects_response.loc[condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ed71d249",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing it out for processing in script\n",
    "redirects_response.loc[condition]['base_redirect'].drop_duplicates().to_csv('./data/redirect_urls.txt', sep='|', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a57ff26",
   "metadata": {},
   "source": [
    "For the `base_redirect`s in these records, I need to check if there is a valid `ads.txt`\n",
    "\n",
    "Since this needs parallelization, it is in a separate script (similar to the one used earlier to check of `ads.txt`) - See `checking_for_adstxt2.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d2cdf09e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_url</th>\n",
       "      <th>base_redirect</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://presstelegram.com/ads.txt</td>\n",
       "      <td>presstelegram.com</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://4.qth.com/ads.txt</td>\n",
       "      <td>4.qth.com</td>\n",
       "      <td>HTTPSConnectionPool(host='4.qth.com', port=443...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://chronicleonline.com/ads.txt</td>\n",
       "      <td>chronicleonline.com</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://usatoday.com/ads.txt</td>\n",
       "      <td>usatoday.com</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://inforum.com/ads.txt</td>\n",
       "      <td>inforum.com</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             query_url        base_redirect  \\\n",
       "0    https://presstelegram.com/ads.txt    presstelegram.com   \n",
       "1            https://4.qth.com/ads.txt            4.qth.com   \n",
       "2  https://chronicleonline.com/ads.txt  chronicleonline.com   \n",
       "3         https://usatoday.com/ads.txt         usatoday.com   \n",
       "4          https://inforum.com/ads.txt          inforum.com   \n",
       "\n",
       "                                            response  \n",
       "0                                                200  \n",
       "1  HTTPSConnectionPool(host='4.qth.com', port=443...  \n",
       "2                                                200  \n",
       "3                                                200  \n",
       "4                                                200  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses2 = pd.read_csv('./data/responses2.txt', sep='|')\n",
    "responses2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d155fddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_url</th>\n",
       "      <th>base_redirect</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>response</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HTTPSConnectionPool(host='4.qth.com', port=443): Max retries exceeded with url: /ads.txt (Caused by NewConnectionError('&lt;urllib3.connection.HTTPSConnection object at 0x0000021443D52200&gt;: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    query_url  base_redirect\n",
       "response                                                                    \n",
       "200                                                        41             41\n",
       "404                                                        12             12\n",
       "HTTPSConnectionPool(host='4.qth.com', port=443)...          1              1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses2.groupby('response').count()\n",
    "#So the 41 must enter the valid redirects list. I must also create the mapping file for them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7299d3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating mapping file\n",
    "mappings = responses2.loc[responses2.response == '200'].merge(redirects_response.loc[condition], how = 'left', \n",
    "                            left_on = 'base_redirect', right_on = 'base_redirect')\n",
    "mappings[['base_url', 'base_redirect']].drop_duplicates().to_csv('./data/redirect_mappings.txt', sep='|', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a94b3029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2516\n",
      "2557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\venki\\AppData\\Local\\Temp\\ipykernel_27184\\2982554147.py:3: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  valid_redirects = valid_redirects.append(responses2.loc[responses2['response'] == '200', 'base_redirect'])\n"
     ]
    }
   ],
   "source": [
    "valid_redirects = redirects_response.loc[redirects_response['valid_redirect'] == True, 'base_url']\n",
    "print(len(valid_redirects))\n",
    "valid_redirects = valid_redirects.append(responses2.loc[responses2['response'] == '200', 'base_redirect'])\n",
    "print(len(valid_redirects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bf6aaeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_redirects = pd.DataFrame(valid_redirects, columns = ['base_url'])\n",
    "valid_redirects.to_csv('./data/valid_redirects.txt', sep='|', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "697ec88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2557"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_redirects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a44e9b2",
   "metadata": {},
   "source": [
    "And with that the cleaning is all done.\n",
    "\n",
    "I am going to do one final check if everything works fine in a script. See `checking_for_adstxt3.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7c82564b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_url</th>\n",
       "      <th>base_redirect</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://okmagazine.com/ads.txt</td>\n",
       "      <td>okmagazine.com</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://vanityfair.com/ads.txt</td>\n",
       "      <td>vanityfair.com</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://drudgereport.com/ads.txt</td>\n",
       "      <td>drudgereport.com</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://pingbacklinks.com/ads.txt</td>\n",
       "      <td>pingbacklinks.com</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://thewalrus.ca/ads.txt</td>\n",
       "      <td>thewalrus.ca</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2549</th>\n",
       "      <td>https://starrgennett.org/ads.txt</td>\n",
       "      <td>starrgennett.org</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2550</th>\n",
       "      <td>https://gevelreinigingen.be/ads.txt</td>\n",
       "      <td>gevelreinigingen.be</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2551</th>\n",
       "      <td>https://leaderunion.com/ads.txt</td>\n",
       "      <td>leaderunion.com</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2552</th>\n",
       "      <td>https://waynecojournalbanner.com/ads.txt</td>\n",
       "      <td>waynecojournalbanner.com</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2553</th>\n",
       "      <td>https://pikecountyexpress.com/ads.txt</td>\n",
       "      <td>pikecountyexpress.com</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2554 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     query_url             base_redirect  \\\n",
       "0               https://okmagazine.com/ads.txt            okmagazine.com   \n",
       "1               https://vanityfair.com/ads.txt            vanityfair.com   \n",
       "2             https://drudgereport.com/ads.txt          drudgereport.com   \n",
       "3            https://pingbacklinks.com/ads.txt         pingbacklinks.com   \n",
       "4                 https://thewalrus.ca/ads.txt              thewalrus.ca   \n",
       "...                                        ...                       ...   \n",
       "2549          https://starrgennett.org/ads.txt          starrgennett.org   \n",
       "2550       https://gevelreinigingen.be/ads.txt       gevelreinigingen.be   \n",
       "2551           https://leaderunion.com/ads.txt           leaderunion.com   \n",
       "2552  https://waynecojournalbanner.com/ads.txt  waynecojournalbanner.com   \n",
       "2553     https://pikecountyexpress.com/ads.txt     pikecountyexpress.com   \n",
       "\n",
       "      response  \n",
       "0        200.0  \n",
       "1        200.0  \n",
       "2        200.0  \n",
       "3        200.0  \n",
       "4        200.0  \n",
       "...        ...  \n",
       "2549     200.0  \n",
       "2550     200.0  \n",
       "2551     200.0  \n",
       "2552     200.0  \n",
       "2553     200.0  \n",
       "\n",
       "[2554 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_check = pd.read_csv('./data/responses_final.txt', sep='|')\n",
    "final_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "28348998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_url</th>\n",
       "      <th>base_redirect</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>response</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200.0</th>\n",
       "      <td>2552</td>\n",
       "      <td>2552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          query_url  base_redirect\n",
       "response                          \n",
       "200.0          2552           2552\n",
       "502.0             1              1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_check.groupby('response').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a64789",
   "metadata": {},
   "source": [
    "Good enough. Moving on..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
